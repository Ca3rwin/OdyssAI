{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"OdyssAI - GePpeTto.ipynb","provenance":[],"collapsed_sections":["JNtU8b-AwsqA"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"38bb513aa8f5433d83fdd3e697b4bcb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a0b3e7d67de49db9d5d0e558a75623d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6fba3ecad2854086adb5a0234cf551ff","IPY_MODEL_a2dc94f5f69f4e4d93349e8c422a90c7"]}},"0a0b3e7d67de49db9d5d0e558a75623d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fba3ecad2854086adb5a0234cf551ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8531ca0a70c34ef1a54d58894719cb58","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1069,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1069,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8e5c721f4394d168f60c752a541fdd3"}},"a2dc94f5f69f4e4d93349e8c422a90c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f30eccf8f0343a897caef18320a9a34","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.07k/1.07k [00:00&lt;00:00, 13.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1bb60ce5cdb447a28c5d197a69b04ba6"}},"8531ca0a70c34ef1a54d58894719cb58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d8e5c721f4394d168f60c752a541fdd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f30eccf8f0343a897caef18320a9a34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1bb60ce5cdb447a28c5d197a69b04ba6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"deb6db3121e749568941bc4a16e9c63b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_698c5f2a8ad74573813f0b394070866c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_43605fa64f4941a2aa07958318d050a9","IPY_MODEL_70e1d1bebcc742c48f43d7d8f9c738e0"]}},"698c5f2a8ad74573813f0b394070866c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43605fa64f4941a2aa07958318d050a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90f84921ef0a4f4eb1fb5f12456cfb24","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":546781,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":546781,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_277469a7a87d41c8b2853d473ee9a067"}},"70e1d1bebcc742c48f43d7d8f9c738e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d87f7c5cde8141f1a4065cb8a51e0a7b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 547k/547k [00:01&lt;00:00, 298kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bfc3bdd6865148d5ac6376784712054c"}},"90f84921ef0a4f4eb1fb5f12456cfb24":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"277469a7a87d41c8b2853d473ee9a067":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d87f7c5cde8141f1a4065cb8a51e0a7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bfc3bdd6865148d5ac6376784712054c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1075f090e334727b8206d596e4bc1b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8467055ebf5140fcae404b3a0fdbb04f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f850ebced24641d7afbc3d00131a973c","IPY_MODEL_4df2a9592ad64f9caa7d3000baa21819"]}},"8467055ebf5140fcae404b3a0fdbb04f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f850ebced24641d7afbc3d00131a973c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80c4c6fa064949ca977a8eb752bbd4a1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":286907,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":286907,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e2f0ee634cf4f899faa8aa18740a894"}},"4df2a9592ad64f9caa7d3000baa21819":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c3ed01bafc7d4ae685c0b46e7bc0cb13","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 287k/287k [00:01&lt;00:00, 262kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a8bd75665e34d6fb8c8f3e41547571a"}},"80c4c6fa064949ca977a8eb752bbd4a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e2f0ee634cf4f899faa8aa18740a894":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3ed01bafc7d4ae685c0b46e7bc0cb13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6a8bd75665e34d6fb8c8f3e41547571a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2d2416c4e2743509167f22f7bb35a40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6534793367624ff1a4a6e8bf38796e41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_90b7279cf3634599ad72eabff346db45","IPY_MODEL_db99d85581d94a4488e0ec87e8de622a"]}},"6534793367624ff1a4a6e8bf38796e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90b7279cf3634599ad72eabff346db45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5b4dc236dd7b48118ec040b619b7c296","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":90,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":90,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0e45b0b76fc4829ac9ee17e10abd98f"}},"db99d85581d94a4488e0ec87e8de622a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33a59e8c2ba34fdfa2afea6cbd29b45f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 90.0/90.0 [00:00&lt;00:00, 168B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fdac2ca092244dedadbec6bc9333b869"}},"5b4dc236dd7b48118ec040b619b7c296":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0e45b0b76fc4829ac9ee17e10abd98f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33a59e8c2ba34fdfa2afea6cbd29b45f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fdac2ca092244dedadbec6bc9333b869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab36fadb8a3d42a0a7d279065e27f10b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5df42fd6329643a991929f684dc2a756","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d4ee007a7aae496e85b5570c8ff107d2","IPY_MODEL_f2358b35b55e4405a29e28c577a321a7"]}},"5df42fd6329643a991929f684dc2a756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4ee007a7aae496e85b5570c8ff107d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a772a4ace9e409aab9830b1cd9a9cdb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2fc22f9cb144aeb9282302e783a2aab"}},"f2358b35b55e4405a29e28c577a321a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7641c57f6f9445d897e0adefab31c0d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 23.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d972ddc6817479186c208fb4edf3c66"}},"6a772a4ace9e409aab9830b1cd9a9cdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f2fc22f9cb144aeb9282302e783a2aab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7641c57f6f9445d897e0adefab31c0d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1d972ddc6817479186c208fb4edf3c66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c66ab0986d3a48b6bc744619cc698ca9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f417b22802a4818acf3496246b6374b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e6de1fa7c4844e8b9b550712635f22ee","IPY_MODEL_b70dd0e94db2410c9ca3805629d013a4"]}},"9f417b22802a4818acf3496246b6374b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6de1fa7c4844e8b9b550712635f22ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dfdf18c702cb400882c6b9bc01e7fdea","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":485894375,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":485894375,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22fa5e02cdfa42ddbc4bfbade4957b44"}},"b70dd0e94db2410c9ca3805629d013a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72942a255e7841d9ab874d003c0f1270","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 486M/486M [00:11&lt;00:00, 42.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96cb11ce9a894cbfbc4aae479308a659"}},"dfdf18c702cb400882c6b9bc01e7fdea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"22fa5e02cdfa42ddbc4bfbade4957b44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72942a255e7841d9ab874d003c0f1270":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"96cb11ce9a894cbfbc4aae479308a659":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"c0Wi8bwcie3g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621855133094,"user_tz":-120,"elapsed":43331,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"2ad3a5c7-bc3a-4baa-dadc-437a06841312"},"source":["!pip install transformers\n","!pip install --upgrade spacy\n","!python -m spacy download it_core_news_sm\n","!pip install --upgrade nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 48.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.1\n","Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 236kB/s \n","\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n","\u001b[K     |████████████████████████████████| 460kB 47.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Collecting pathy>=0.3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Collecting spacy-legacy<3.1.0,>=3.0.4\n","  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n","Collecting catalogue<2.1.0,>=2.0.3\n","  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n","Collecting pydantic<1.8.0,>=1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n","\u001b[K     |████████████████████████████████| 9.1MB 50.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Collecting typer<0.4.0,>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Collecting thinc<8.1.0,>=8.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 43.9MB/s \n","\u001b[?25hCollecting smart-open<4.0.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n","\u001b[K     |████████████████████████████████| 122kB 60.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.0)\n","Collecting click<7.2.0,>=7.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: smart-open\n","  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=2a379688f239506cbe491b50773cfeaa07baab6fd6b4a253abbe626e5937770b\n","  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n","Successfully built smart-open\n","Installing collected packages: catalogue, srsly, click, typer, smart-open, pathy, spacy-legacy, pydantic, thinc, spacy\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Found existing installation: click 8.0.0\n","    Uninstalling click-8.0.0:\n","      Successfully uninstalled click-8.0.0\n","  Found existing installation: smart-open 5.0.0\n","    Uninstalling smart-open-5.0.0:\n","      Successfully uninstalled smart-open-5.0.0\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.4 click-7.1.2 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n","2021-05-24 11:18:42.253958: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Collecting it-core-news-sm==3.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.0.0/it_core_news_sm-3.0.0-py3-none-any.whl (17.1MB)\n","\u001b[K     |████████████████████████████████| 17.1MB 179kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from it-core-news-sm==3.0.0) (3.0.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (20.9)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (0.3.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (0.4.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.4.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (4.41.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (1.0.5)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.7.4.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (0.8.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.0.4)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (1.19.5)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (0.5.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.0.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.11.3)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (8.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (56.1.0)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (1.7.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.4.7)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (7.1.2)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.4.1)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (3.0.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->it-core-news-sm==3.0.0) (2.0.0)\n","Installing collected packages: it-core-news-sm\n","Successfully installed it-core-news-sm-3.0.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('it_core_news_sm')\n","Collecting nltk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 7.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n","Installing collected packages: nltk\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FgtR6AAjDjW0"},"source":["!pip freeze > requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P_ToFIQeWs0t","colab":{"base_uri":"https://localhost:8080/","height":262,"referenced_widgets":["38bb513aa8f5433d83fdd3e697b4bcb3","0a0b3e7d67de49db9d5d0e558a75623d","6fba3ecad2854086adb5a0234cf551ff","a2dc94f5f69f4e4d93349e8c422a90c7","8531ca0a70c34ef1a54d58894719cb58","d8e5c721f4394d168f60c752a541fdd3","0f30eccf8f0343a897caef18320a9a34","1bb60ce5cdb447a28c5d197a69b04ba6","deb6db3121e749568941bc4a16e9c63b","698c5f2a8ad74573813f0b394070866c","43605fa64f4941a2aa07958318d050a9","70e1d1bebcc742c48f43d7d8f9c738e0","90f84921ef0a4f4eb1fb5f12456cfb24","277469a7a87d41c8b2853d473ee9a067","d87f7c5cde8141f1a4065cb8a51e0a7b","bfc3bdd6865148d5ac6376784712054c","e1075f090e334727b8206d596e4bc1b3","8467055ebf5140fcae404b3a0fdbb04f","f850ebced24641d7afbc3d00131a973c","4df2a9592ad64f9caa7d3000baa21819","80c4c6fa064949ca977a8eb752bbd4a1","6e2f0ee634cf4f899faa8aa18740a894","c3ed01bafc7d4ae685c0b46e7bc0cb13","6a8bd75665e34d6fb8c8f3e41547571a","c2d2416c4e2743509167f22f7bb35a40","6534793367624ff1a4a6e8bf38796e41","90b7279cf3634599ad72eabff346db45","db99d85581d94a4488e0ec87e8de622a","5b4dc236dd7b48118ec040b619b7c296","d0e45b0b76fc4829ac9ee17e10abd98f","33a59e8c2ba34fdfa2afea6cbd29b45f","fdac2ca092244dedadbec6bc9333b869","ab36fadb8a3d42a0a7d279065e27f10b","5df42fd6329643a991929f684dc2a756","d4ee007a7aae496e85b5570c8ff107d2","f2358b35b55e4405a29e28c577a321a7","6a772a4ace9e409aab9830b1cd9a9cdb","f2fc22f9cb144aeb9282302e783a2aab","7641c57f6f9445d897e0adefab31c0d7","1d972ddc6817479186c208fb4edf3c66"]},"executionInfo":{"status":"ok","timestamp":1621855138051,"user_tz":-120,"elapsed":4961,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"20f0a674-76ea-4190-895c-adad84b3f629"},"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"LorenzoDeMattei/GePpeTto\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38bb513aa8f5433d83fdd3e697b4bcb3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1069.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"deb6db3121e749568941bc4a16e9c63b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=546781.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1075f090e334727b8206d596e4bc1b3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=286907.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2d2416c4e2743509167f22f7bb35a40","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=90.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab36fadb8a3d42a0a7d279065e27f10b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZlwRwu8KtJoP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621855145068,"user_tz":-120,"elapsed":7019,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"4763892c-4ec8-42a6-f792-b04ed2981d31"},"source":["!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=16M7ZFtSByUQ1OWczjIajCAMua89mXgfq' -O testing.txt\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YKoi3m1W7b-_w8LS3bQF3Ps3EK9ha7QR' -O testing_min_tokens_8.txt\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1qmv3PGq-R1Ao-DrjT2oFozSRrrVfBmGT' -O training.txt\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1XWUfOmzB1CmjxEF03sg8DoF3u8BoArni' -O validation.txt\n","# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Ql23NJjVNA0V31EvoiaCYdrBHTnGqRgX' -O complete_dataset_sentences_full.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-24 11:18:58--  https://docs.google.com/uc?export=download&id=16M7ZFtSByUQ1OWczjIajCAMua89mXgfq\n","Resolving docs.google.com (docs.google.com)... 74.125.142.100, 74.125.142.101, 74.125.142.102, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.142.100|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0g-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7llegopjvna2d91f9ak9sjj73vcfkee0/1621855125000/03570075665403880665/*/16M7ZFtSByUQ1OWczjIajCAMua89mXgfq?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-24 11:18:59--  https://doc-0g-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7llegopjvna2d91f9ak9sjj73vcfkee0/1621855125000/03570075665403880665/*/16M7ZFtSByUQ1OWczjIajCAMua89mXgfq?e=download\n","Resolving doc-0g-3o-docs.googleusercontent.com (doc-0g-3o-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n","Connecting to doc-0g-3o-docs.googleusercontent.com (doc-0g-3o-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 567180 (554K) [text/plain]\n","Saving to: ‘testing.txt’\n","\n","testing.txt         100%[===================>] 553.89K  --.-KB/s    in 0.005s  \n","\n","2021-05-24 11:19:00 (114 MB/s) - ‘testing.txt’ saved [567180/567180]\n","\n","--2021-05-24 11:19:00--  https://docs.google.com/uc?export=download&id=1YKoi3m1W7b-_w8LS3bQF3Ps3EK9ha7QR\n","Resolving docs.google.com (docs.google.com)... 74.125.195.139, 74.125.195.113, 74.125.195.102, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.195.139|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-00-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7firlhhcvk2h9tmpliqg09ek7tqm5hbv/1621855125000/03570075665403880665/*/1YKoi3m1W7b-_w8LS3bQF3Ps3EK9ha7QR?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-24 11:19:01--  https://doc-00-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7firlhhcvk2h9tmpliqg09ek7tqm5hbv/1621855125000/03570075665403880665/*/1YKoi3m1W7b-_w8LS3bQF3Ps3EK9ha7QR?e=download\n","Resolving doc-00-3o-docs.googleusercontent.com (doc-00-3o-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n","Connecting to doc-00-3o-docs.googleusercontent.com (doc-00-3o-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 514523 (502K) [text/plain]\n","Saving to: ‘testing_min_tokens_8.txt’\n","\n","testing_min_tokens_ 100%[===================>] 502.46K  --.-KB/s    in 0.004s  \n","\n","2021-05-24 11:19:01 (139 MB/s) - ‘testing_min_tokens_8.txt’ saved [514523/514523]\n","\n","--2021-05-24 11:19:01--  https://docs.google.com/uc?export=download&id=1qmv3PGq-R1Ao-DrjT2oFozSRrrVfBmGT\n","Resolving docs.google.com (docs.google.com)... 74.125.195.139, 74.125.195.113, 74.125.195.102, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.195.139|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0g-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/res0dduvelmuhh9ugb0btkpgvnllekci/1621855125000/03570075665403880665/*/1qmv3PGq-R1Ao-DrjT2oFozSRrrVfBmGT?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-24 11:19:03--  https://doc-0g-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/res0dduvelmuhh9ugb0btkpgvnllekci/1621855125000/03570075665403880665/*/1qmv3PGq-R1Ao-DrjT2oFozSRrrVfBmGT?e=download\n","Resolving doc-0g-3o-docs.googleusercontent.com (doc-0g-3o-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n","Connecting to doc-0g-3o-docs.googleusercontent.com (doc-0g-3o-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/plain]\n","Saving to: ‘training.txt’\n","\n","training.txt            [ <=>                ]   4.29M  26.3MB/s    in 0.2s    \n","\n","2021-05-24 11:19:04 (26.3 MB/s) - ‘training.txt’ saved [4504521]\n","\n","--2021-05-24 11:19:04--  https://docs.google.com/uc?export=download&id=1XWUfOmzB1CmjxEF03sg8DoF3u8BoArni\n","Resolving docs.google.com (docs.google.com)... 74.125.195.100, 74.125.195.138, 74.125.195.113, ...\n","Connecting to docs.google.com (docs.google.com)|74.125.195.100|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-10-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/k5dfvodua8e8elm8h7ekal4cj3ottd02/1621855125000/03570075665403880665/*/1XWUfOmzB1CmjxEF03sg8DoF3u8BoArni?e=download [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-05-24 11:19:05--  https://doc-10-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/k5dfvodua8e8elm8h7ekal4cj3ottd02/1621855125000/03570075665403880665/*/1XWUfOmzB1CmjxEF03sg8DoF3u8BoArni?e=download\n","Resolving doc-10-3o-docs.googleusercontent.com (doc-10-3o-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n","Connecting to doc-10-3o-docs.googleusercontent.com (doc-10-3o-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 564765 (552K) [text/plain]\n","Saving to: ‘validation.txt’\n","\n","validation.txt      100%[===================>] 551.53K  --.-KB/s    in 0.004s  \n","\n","2021-05-24 11:19:05 (124 MB/s) - ‘validation.txt’ saved [564765/564765]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bgrtXcryAzT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621770671445,"user_tz":-120,"elapsed":19314,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"e4c6645e-7e84-421e-84e1-d7c14873ef9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iT6rPH7oKKuS"},"source":["# Remove unwanted files\n","\n","!rm /content/pytorch_model.bin /content/special_tokens_map.json /content/tokenizer_config.json /content/training_args.bin /content/vocab.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kg9dpP-QzHGO"},"source":["# Python implementation of Naive method\n","# to print all divisors\n"," \n","# method to print the divisors\n","def printDivisors(n) :\n","    i = 1\n","    while i <= n :\n","        if (n % i==0) :\n","            print(i),\n","        i = i + 1\n","\n","# Driver method\n","n = int(input(\"Enter the number you want to find the divisors of: \"))\n","print(f\"The divisors of {n} are: \")\n","printDivisors(n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qn5FkqLIyNJx"},"source":["# Esegui la cella per caricare il modello già presente"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x4ADOqAhA8y","executionInfo":{"status":"ok","timestamp":1621772089011,"user_tz":-120,"elapsed":11084,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"ed175659-db48-4d7b-9cad-69c54cd39cb3"},"source":["# Get large file from G-Drive\n","# wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=FILEID\" -O FILENAME && rm -rf /tmp/cookies.txt\n","\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4\" -O OdyssAI_Final_2.0.zip && rm -rf /tmp/cookies.txt\n","\n","!unzip 'OdyssAI_Final_2.0.zip'\n","!rm OdyssAI_Final_2.0.zip\n","\n","model_output_dir = 'OdyssAI_Final_2.0'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-23 12:14:40--  https://docs.google.com/uc?export=download&confirm=dhpR&id=1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4\n","Resolving docs.google.com (docs.google.com)... 172.217.12.238, 2607:f8b0:4004:807::200e\n","Connecting to docs.google.com (docs.google.com)|172.217.12.238|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e=download [following]\n","--2021-05-23 12:14:40--  https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e=download\n","Resolving doc-04-0c-docs.googleusercontent.com (doc-04-0c-docs.googleusercontent.com)... 172.217.8.1, 2607:f8b0:4004:803::2001\n","Connecting to doc-04-0c-docs.googleusercontent.com (doc-04-0c-docs.googleusercontent.com)|172.217.8.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://docs.google.com/nonceSigner?nonce=u5innfllgk3q6&continue=https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e%3Ddownload&hash=2uo9nnqu4o5vk0m8qb8ci6ijgjdu33mm [following]\n","--2021-05-23 12:14:40--  https://docs.google.com/nonceSigner?nonce=u5innfllgk3q6&continue=https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e%3Ddownload&hash=2uo9nnqu4o5vk0m8qb8ci6ijgjdu33mm\n","Connecting to docs.google.com (docs.google.com)|172.217.12.238|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e=download&nonce=u5innfllgk3q6&user=13459996287686288009Z&hash=bd2nc657n3m5mf63ud4bdluhq0qbh14g [following]\n","--2021-05-23 12:14:40--  https://doc-04-0c-docs.googleusercontent.com/docs/securesc/r6dt499nfmd8df1036vqror1oobaokup/vdkfonq7d23rsc0ugi2dguu8fg2rogi6/1621772025000/03570075665403880665/13459996287686288009Z/1ka7_lKgHYhu0cDi5t1TOnD0tqC2aRQs4?e=download&nonce=u5innfllgk3q6&user=13459996287686288009Z&hash=bd2nc657n3m5mf63ud4bdluhq0qbh14g\n","Connecting to doc-04-0c-docs.googleusercontent.com (doc-04-0c-docs.googleusercontent.com)|172.217.8.1|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-zip-compressed]\n","Saving to: ‘OdyssAI_Final_2.0.zip’\n","\n","OdyssAI_Final_2.0.z     [              <=>   ] 386.10M  96.7MB/s    in 4.4s    \n","\n","2021-05-23 12:14:45 (87.3 MB/s) - ‘OdyssAI_Final_2.0.zip’ saved [404855260]\n","\n","Archive:  OdyssAI_Final_2.0.zip\n","   creating: OdyssAI_Final_2.0/\n","  inflating: OdyssAI_Final_2.0/tokenizer.json  \n","  inflating: OdyssAI_Final_2.0/training_args.bin  \n","  inflating: OdyssAI_Final_2.0/special_tokens_map.json  \n","  inflating: OdyssAI_Final_2.0/config.json  \n","  inflating: OdyssAI_Final_2.0/tokenizer_config.json  \n","  inflating: OdyssAI_Final_2.0/vocab.json  \n","  inflating: OdyssAI_Final_2.0/merges.txt  \n","  inflating: OdyssAI_Final_2.0/pytorch_model.bin  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JNtU8b-AwsqA"},"source":["# Esegui le seguenti celle SOLO per fare training su un nuovo dataset"]},{"cell_type":"code","metadata":{"id":"iYuT-WeM3qyv"},"source":["train_path = 'training.txt'\n","validation_path = 'validation.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEYuXa7PXI8m","executionInfo":{"status":"ok","timestamp":1621855149106,"user_tz":-120,"elapsed":4045,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"348aa55f-23d3-4bda-fc78-0aa1a3f9d2a9"},"source":["from transformers import TextDataset, DataCollatorForLanguageModeling, LineByLineTextDataset\n","\n","\"\"\"Carica training e validation set insieme al data collator\"\"\"\n","def load_dataset(train_path,validation_path,tokenizer):\n","  train_dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path=train_path, block_size=128)\n","  validation_dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path=validation_path, block_size=128)\n","  data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","  return train_dataset,validation_dataset,data_collator\n","\n","train_dataset, validation_dataset, data_collator = load_dataset(train_path,validation_path,tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:124: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eaqIQ72d0RYj"},"source":["from datetime import datetime\n"," \n","dt_string = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n","model_output_dir = f\"OdyssAI_{dt_string}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMTyi4QibcTr","executionInfo":{"status":"ok","timestamp":1621775257124,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"da275dc6-d9f5-49dc-d5c8-ae31c81fc07d"},"source":["print(model_output_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["OdyssAI_23-05-2021_13-07-38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKyM4y36ejJ5","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["c66ab0986d3a48b6bc744619cc698ca9","9f417b22802a4818acf3496246b6374b","e6de1fa7c4844e8b9b550712635f22ee","b70dd0e94db2410c9ca3805629d013a4","dfdf18c702cb400882c6b9bc01e7fdea","22fa5e02cdfa42ddbc4bfbade4957b44","72942a255e7841d9ab874d003c0f1270","96cb11ce9a894cbfbc4aae479308a659"]},"executionInfo":{"status":"ok","timestamp":1621855172697,"user_tz":-120,"elapsed":23598,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"24599dab-46cf-45f0-adfc-618d010c6c63"},"source":["from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n"," \n","model = AutoModelForCausalLM.from_pretrained(\"LorenzoDeMattei/GePpeTto\")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","train_batch_size = 32\n","\n","training_args = TrainingArguments (\n","    # directory di output\n","    output_dir = model_output_dir, \n","    # sovrascrive il contenuto della directory di output, nel caso fosse già presente\n","    overwrite_output_dir = True, \n","    # numero di epoche per il training\n","    num_train_epochs = 10, \n","    # grandezza del batch di training\n","    per_device_train_batch_size = train_batch_size, \n","    # grandezza del batch di validation\n","    per_device_eval_batch_size = 64,  \n","    # quanti step fare prima di mostrare il log della training loss\n","    logging_steps = int(len(train_dataset)/train_batch_size), \n","    # quanti step fare prima di salvare un checkpoint del modello\n","    save_steps = 3200, \n","    # numero di step di \"riscaldamento\" fatti ad un learning rate ridotto\n","    warmup_steps = 500, \n","    # la validazione viene compiuta ad ogni epoca di training\n","    evaluation_strategy = \"epoch\" \n","    )\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    tokenizer=tokenizer)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c66ab0986d3a48b6bc744619cc698ca9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=485894375.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"4gLGqnuGfS0_","executionInfo":{"status":"ok","timestamp":1621864897180,"user_tz":-120,"elapsed":9724293,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"6991865c-1045-4cc1-f61f-2f54284980f3"},"source":["trainer.train()\n","trainer.save_model()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='19130' max='19130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19130/19130 2:42:02, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.773900</td>\n","      <td>3.540869</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.316600</td>\n","      <td>3.486959</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.016500</td>\n","      <td>3.511123</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.763500</td>\n","      <td>3.571551</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.541300</td>\n","      <td>3.646890</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.346200</td>\n","      <td>3.737813</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.184300</td>\n","      <td>3.804130</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.049800</td>\n","      <td>3.862078</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.943400</td>\n","      <td>3.905762</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.866500</td>\n","      <td>3.926932</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Z60yyl2ujoMa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdHTrrPk4f0E"},"source":["# Zips and saves model on Drive\n","\n","\n","model_save_dir = f\"OdyssAI_{dt_string}.zip\"\n","!zip -r OdyssAI.zip \"$model_output_dir\"\n","# !mkdir \"/content/drive/My Drive/OdyssAI/Models/$model_save_dir\"\n","!cp OdyssAI.zip \"/content/drive/My Drive/OdyssAI/Models_GePpeTto/$model_save_dir\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GIhT98iF1yHe"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"ZLYAO9KJlxYH"},"source":["from transformers import pipeline\n","\n","odyssai = pipeline('text-generation', model=model_output_dir, tokenizer=tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RB9i6xAUdg0s"},"source":["import numpy as np\n","from scipy import stats\n","\n","def textManipulation (output):\n","  replace_new_line = output.replace('\\n', ' ')                                          # Replaces newlines with spaces to keep the sentence in one line\n","  hyp_doc = nlp(replace_new_line) \n","  return hyp_doc\n","\n","def writeOnFile (input_file, input_list):\n","  input_file.write('Score:\\n' + str(input_list) + '\\n\\n' +\n","              'Mean: ' + str(np.mean(input_list)) + '\\n' +\n","              'Median: ' + str(np.median(input_list)) + '\\n' +\n","              'Mode: ' + str(stats.mode(input_list)[0][0]) + '\\t\\t\\tCount: ' + str(stats.mode(input_list)[1][0]) + '\\n' +\n","              'Max: ' + str(np.max(input_list)) + '\\t\\t\\tMin: ' + str(np.min(input_list)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kSFNK9roreX"},"source":["# BLEU SCORE - RESTART FROM CHECKPOINT\n","from nltk.translate.bleu_score import sentence_bleu\n","import spacy\n","import numpy as np\n","from scipy import stats\n","\n","nlp = spacy.load('it_core_news_sm')\n","f = open('testing_min_tokens_8.txt', 'r')\n","lines = f.readlines()\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YTEyovM7hfxr","executionInfo":{"status":"error","timestamp":1621770228016,"user_tz":-120,"elapsed":26091,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"1dc5a0c4-f417-448d-9b5a-96ac6f713943"},"source":["# BLEU SCORE\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from os import path\n","import spacy\n","\n","CHECKPOINT = 800                                                                # After how many lines a checkpoint is saved\n","min_prompt = 4                                                                  # Minimum prompt size (in tokens)\n","max_prompt = 4                                                                  # Maximum prompt size (in tokens)\n","nlp = spacy.load('it_core_news_sm')\n","\n","f = open('testing_min_tokens_8.txt', 'r')\n","lines = f.readlines()\n","f.close()\n","\n","cc = SmoothingFunction()\n","\n","for prompt_size in range(min_prompt, max_prompt + 1):                           # max_prompt + 1 because range(1, 4) returns 1, 2, 3\n","\n","  scores = []\n","  len_diffs = []\n","\n","  for line_counter, line in enumerate(lines):\n","    reference = [[]]\n","    hypotesis = []\n","    print(f'Line {line_counter+1}')\n","    ref_doc = nlp(line.replace('\\n', ''))\n","\n","    for ref_doc_counter, token in enumerate(ref_doc):\n","      reference[0].append(str(token))\n","    \n","    print(f'Reference: {ref_doc_counter + 1}\\t{reference}')\n","    prompt = str(ref_doc[0:prompt_size])\n","    output = odyssai(prompt, max_length = ref_doc_counter + 10,\n","                    top_k = 50, top_p = 0.95,\n","                    do_sample = True, clean_up_tokenization_spaces = True)\n","    \n","    hyp_doc = textManipulation(output[0]['generated_text'])\n","\n","    for hyp_doc_counter, token in enumerate(hyp_doc):\n","      hypotesis.append(str(token))\n","\n","    print(f'Hypotesis: {hyp_doc_counter + 1}\\t{hypotesis}')\n","    len_diff = ref_doc_counter - hyp_doc_counter\n","    print(f'Length difference: {len_diff}')\n","    score = sentence_bleu(reference, hypotesis, smoothing_function=cc.method4)\n","    print(f'BLEU SCORE: {score}')\n","    print(100 * '-')\n","    scores.append(score)\n","    len_diffs.append(ref_doc_counter - hyp_doc_counter)\n","\n","    if (line_counter + 1) % CHECKPOINT == 0:\n","      f = open(f'bleu_scores_prompt{prompt_size}_{line_counter+1}.txt', 'w+')\n","      f1 = open(f'length_difference_prompt{prompt_size}_{line_counter+1}.txt', 'w+')\n","      writeOnFile(f, scores)\n","      writeOnFile(f1, len_diffs)\n","      f.close()\n","      f1.close()\n","      !cp bleu_scores_prompt{prompt_size}_{line_counter+1}.txt \"/content/drive/My Drive/OdyssAI/Models\"\n","\n","  f = open(f'bleu_scores_prompt{prompt_size}.txt', 'w+')\n","  f1 = open(f'length_difference_prompt{prompt_size}.txt', 'w+')\n","  writeOnFile(f, scores)\n","  writeOnFile(f1, len_diffs)\n","  f.close()\n","  f1.close()\n","  # while not path.exists(f\"/content/drive/My Drive/OdyssAI/Models/BLEU/bleu_scores_prompt{prompt_size}.txt\"):\n","  !mkdir -p \"/content/drive/My Drive/OdyssAI/Models_GePpeTto/BLEU\"\n","  !cp bleu_scores_prompt{prompt_size}.txt \"/content/drive/My Drive/OdyssAI/Models_GePpeTto/BLEU\"\n","  # while not path.exists(f\"/content/drive/My Drive/OdyssAI/Models/BLEU/length_difference_prompt{prompt_size}.txt\"):\n","  !cp length_difference_prompt{prompt_size}.txt \"/content/drive/My Drive/OdyssAI/Models_GePpeTto/BLEU\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Line 1\n","Reference: 9\t[['Le', 'viscere', 'gli', 'si', 'strinsero', 'come', 'un', 'pugno', '.']]\n","Hypotesis: 10\t['Le', 'viscere', 'gli', 'si', 'appiccicassero', 'di', 'nuovo', 'dalla', 'fronte', '.']\n","Length difference: -1\n","BLEU SCORE: 0.2777619034011791\n","----------------------------------------------------------------------------------------------------\n","Line 2\n","Reference: 28\t[['E', 'lì', 'essa', 'rimase', ',', 'che', 'Eöl', 'se', 'la', 'prese', 'in', 'moglie', ',', 'e', 'lungo', 'tempo', 'passò', 'prima', 'che', 'alcuno', 'della', 'sua', 'stirpe', 'ne', 'avesse', 'nuovamente', 'notizia', '.']]\n","Hypotesis: 25\t['E', 'lì', 'essa', 'rimase', 'immobile', '.', 'Nel', 'buio', 'buio', ',', 'solo', 'ombre', ',', 'stelle', 'li', 'osservarono', ':', 'non', \"c'\", 'era', 'nulla', 'sotto', 'di', 'lei', '.']\n","Length difference: 3\n","BLEU SCORE: 0.0961881435761692\n","----------------------------------------------------------------------------------------------------\n","Line 3\n","Reference: 8\t[['Io', 'non', 'so', 'cosa', 'veramente', 'sia', 'svenire', ';']]\n","Hypotesis: 14\t['Io', 'non', 'so', 'cosa', 'mi', 'succede', 'e', 'non', 'voglio', 'che', 'nulla', 'mi', 'succede', '.']\n","Length difference: -6\n","BLEU SCORE: 0.1777835117834348\n","----------------------------------------------------------------------------------------------------\n","Line 4\n","Reference: 18\t[['Se', 'non', 'ti', 'do', 'qualche', 'consiglio', 'non', 'te', 'la', 'cavi', ',', 'questo', 'è', 'quanto', 'io', 'posso', 'dire', '.']]\n","Hypotesis: 25\t['Se', 'non', 'ti', 'do', 'le', 'mani', ',', 'ti', 'consiglio', 'di', 'farti', 'i', 'fatti', 'vostri', '.', '\"', 'disse', 'lo', 'stregone', '.', '\"', 'Lo', 'stregone', 'annuì', '.']\n","Length difference: -7\n","BLEU SCORE: 0.10845182904139573\n","----------------------------------------------------------------------------------------------------\n","Line 5\n","Reference: 16\t[['Mi', 'ha', 'sempre', 'incuriosito', ',', 'strigo', ',', 'perché', 'la', 'gente', 'abbia', 'tanta', 'paura', 'di', 'voi', '.']]\n","Hypotesis: 20\t['Mi', 'ha', 'sempre', 'incuriosito', '.', 'È', 'stata', \"un'\", 'infamia', '.', 'È', 'stato', 'un', 'errore', '.', 'È', 'stata', 'una', 'colpa', '.']\n","Length difference: -4\n","BLEU SCORE: 0.12673718536830808\n","----------------------------------------------------------------------------------------------------\n","Line 6\n","Reference: 10\t[['Colpirlo', 'con', 'una', 'spada', ',', 'con', 'tutte', 'le', 'forze', '.']]\n","Hypotesis: 10\t['Colpirlo', 'con', 'una', 'spada', 'non', 'gli', 'sfuggì', 'di', 'mano', '.']\n","Length difference: 0\n","BLEU SCORE: 0.2777619034011791\n","----------------------------------------------------------------------------------------------------\n","Line 7\n","Reference: 15\t[['E', 'avrei', 'potuto', 'favorire', 'meglio', 'il', 'mio', 'sangue', ',', 'anche', 'se', 'fossi', 'giunto', 'prima', '?']]\n","Hypotesis: 15\t['E', 'avrei', 'potuto', 'favorire', 'le', 'mie', 'indagini', 'con', 'lo', 'studio', 'di', 'un', 'solo', 'uomo', '.']\n","Length difference: 0\n","BLEU SCORE: 0.16451929399933107\n","----------------------------------------------------------------------------------------------------\n","Line 8\n","Reference: 12\t[['Gli', 'avete', 'promesso', 'la', 'grazia', 'se', 'fosse', 'diventato', 'testimone', 'della', 'corona', '.']]\n","Hypotesis: 14\t['Gli', 'avete', 'promesso', 'la', 'grazia', '.', 'E', 'sapete', 'bene', 'che', 'cosa', 'sta', 'facendo', '.']\n","Length difference: -2\n","BLEU SCORE: 0.27824623288353134\n","----------------------------------------------------------------------------------------------------\n","Line 9\n","Reference: 11\t[['Immediatamente', ',', 'la', 'cicatrice', 'di', 'Harry', 'parve', 'aprirsi', 'di', 'nuovo', '.']]\n","Hypotesis: 11\t['Immediatamente', ',', 'la', 'cicatrice', 'di', 'Harry', 'si', 'aprì', 'di', 'colpo', '.']\n","Length difference: 0\n","BLEU SCORE: 0.49616830003403634\n","----------------------------------------------------------------------------------------------------\n","Line 10\n","Reference: 10\t[['Non', \"l'\", 'ho', 'visto', 'a', 'nessuna', 'tavola', ',', 'stasera', '.']]\n","Hypotesis: 12\t['Non', \"l'\", 'ho', 'visto', '.', 'Non', 'sono', 'stato', 'io', 'a', 'ucciderti', '.']\n","Length difference: -2\n","BLEU SCORE: 0.23462350320528\n","----------------------------------------------------------------------------------------------------\n","Line 11\n","Reference: 14\t[['\"', 'vai', 'da', 'Olivander', 'e', 'avrai', 'il', 'meglio', ',', 'parlando', 'di', 'bacchette', '\"', '.']]\n","Hypotesis: 13\t['\"', 'vai', 'da', 'Olivander', '\"', 'borbottò', 'Ron', ',', '\"', 'è', 'andata', 'diversamente', '.']\n","Length difference: 1\n","BLEU SCORE: 0.20595660955382236\n","----------------------------------------------------------------------------------------------------\n","Line 12\n","Reference: 21\t[['Correva', 'su', 'creste', ',', 'sentieri', 'ripidi', 'e', 'cenge', 'così', 'strette', 'che', 'Geralt', 'chiudeva', 'gli', 'occhi', 'per', 'non', 'guardare', 'in', 'basso', '.']]\n","Hypotesis: 23\t['Correva', 'su', 'creste', ',', 'creste', 'e', 'alture', 'che', 'non', 'fossero', 'una', 'sola', 'cresta', ';', 'e', 'sopra', 'la', 'valle', 'scorreva', 'un', 'corso', \"d'\", 'acqua']\n","Length difference: -2\n","BLEU SCORE: 0.11856660123276004\n","----------------------------------------------------------------------------------------------------\n","Line 13\n","Reference: 22\t[['ora', 'avrebbe', 'saputo', 'tutte', 'le', 'cose', 'che', 'lui', 'non', 'aveva', 'mai', 'ritenuto', 'di', 'raccon-', 'targli', ',', 'che', 'lo', 'volesse', 'o', 'no', '.']]\n","Hypotesis: 17\t['ora', 'avrebbe', 'saputo', 'tutte', 'le', 'cose', 'di', 'Gondolin', 'e', 'le', 'parole', 'di', 'Melian', 'scritta', 'in', 'rune', '.']\n","Length difference: 5\n","BLEU SCORE: 0.2256210357039155\n","----------------------------------------------------------------------------------------------------\n","Line 14\n","Reference: 22\t[['Quello', 'di', 'Serpeverde', 'rimase', 'deserto', ',', 'ma', 'alcuni', 'dei', 'Corvonero', 'più', 'anziani', 'restarono', 'seduti', 'mentre', 'i', 'loro', 'compagni', 'uscivano', 'in', 'fila', ':']]\n","Hypotesis: 18\t['Quello', 'di', 'Serpeverde', 'rimase', 'in', 'sella', '.', 'James', 'lo', 'fissò', 'di', 'lato', '.', '\"', 'Non', 'mi', 'sembra', '.']\n","Length difference: 4\n","BLEU SCORE: 0.11383800122282604\n","----------------------------------------------------------------------------------------------------\n","Line 15\n","Reference: 18\t[[\"c'\", 'erano', 'delle', 'grosse', 'pietre', 'bianche', ',', 'levigate', 'dal', 'mare', ',', 'a', 'segnare', 'il', 'bordo', 'delle', 'aiuole', '.']]\n","Hypotesis: 17\t[\"c'\", 'erano', 'delle', 'grosse', 'zampe', 'lunghe', 'e', 'sottili', ',', 'che', 'emanavano', 'un', 'forte', 'odore', 'di', 'muschio', '.']\n","Length difference: 1\n","BLEU SCORE: 0.14939354788683523\n","----------------------------------------------------------------------------------------------------\n","Line 16\n","Reference: 37\t[['Un', 'carradore', 'che', 'è', 'scappato', 'da', 'Dun', 'Dâre', 'ed', 'è', 'venuto', 'da', 'noi', 'con', 'la', 'moglie', 'e', 'la', 'figlia', 'ha', 'detto', '...', 'prima', 'al', 'mondo', \"c'\", 'erano', 'gli', 'strighi', '...', 'loro', 'mettevano', 'a', 'posto', 'ogni', 'canagliata', '.']]\n","Hypotesis: 26\t['Un', 'carradore', 'che', 'è', 'come', 'un', 'rapanello', ':', 'lo', 'percordi', ',', 'lo', 'osservi', ',', 'il', 'lampo', 'sprizza', \"dall'\", 'oscurità', '.', 'Fatti', 'da', 'parte', ',', 'guarda', '.']\n","Length difference: 11\n","BLEU SCORE: 0.06555752413086342\n","----------------------------------------------------------------------------------------------------\n","Line 17\n","Reference: 17\t[['Triss', 'Merigold', 'trattiene', 'i', 'suoi', 'magnifici', 'capelli', 'castani', ',', 'agitati', 'e', 'scompigliati', 'da', 'folate', 'di', 'vento', '.']]\n","Hypotesis: 19\t['Triss', 'Merigold', 'trattiene', 'i', 'capelli', 'al', 'vento', ',', 'come', 'una', 'spugna', 'chiodata', ',', 'con', 'lo', 'sguardo', 'che', 'si', 'posava']\n","Length difference: -2\n","BLEU SCORE: 0.1457684614972261\n","----------------------------------------------------------------------------------------------------\n","Line 18\n","Reference: 20\t[['Morwen', 'però', 'rimase', 'in', 'Doriath', 'con', 'Nienor', ',', 'entrambe', 'ospiti', 'di', 'Thingol', 'e', 'Melian', ',', 'trattate', 'con', 'grande', 'onore', '.']]\n","Hypotesis: 24\t['Morwen', 'però', 'rimase', 'in', 'silenzio', ',', 'e', 'nel', 'silenzio', 'si', 'sentì', 'male', 'per', \"l'\", 'orgoglio', ';', 'e', 'allora', 'Tùrin', 'le', 'ordinò', 'di', 'andarsene', 'da']\n","Length difference: -4\n","BLEU SCORE: 0.11328360454400997\n","----------------------------------------------------------------------------------------------------\n","Line 19\n","Reference: 23\t[['La', 'verità', 'è', 'che', 'noi', 'possiamo', 'sbrigarcela', 'col', 'drago', 'anche', 'senza', 'Niedamir', ',', 'mentre', 'Niedamir', 'non', 'può', 'fare', 'a', 'meno', 'di', 'noi', '.']]\n","Hypotesis: 27\t['La', 'verità', 'è', 'che', 'è', 'una', 'maga', '.', 'Non', 'ama', 'i', 'bordelli', '.', 'E', 'neppure', 'i', 'maghi', '.', 'La', 'verità', 'è', 'che', 'non', 'ama', 'i', 'maghi', '.']\n","Length difference: -4\n","BLEU SCORE: 0.09615094003919297\n","----------------------------------------------------------------------------------------------------\n","Line 20\n","Reference: 40\t[['Le', 'galline', 'erano', 'state', 'rinchiuse', ',', 'il', 'cortile', 'spazzato', 'e', 'il', 'giardino', 'accanto', 'potato', ',', 'ripulito', 'e', 'agghindato', ',', 'anche', 'se', 'Harry', ',', 'a', 'cui', 'piaceva', 'più', 'selvatico', ',', 'lo', 'trovava', 'triste', 'senza', 'il', 'consueto', 'drappello', 'di', 'gnomi', 'saltellanti', '.']]\n","Hypotesis: 40\t['Le', 'galline', 'erano', 'state', 'rannicchiate', 'tanto', 'da', 'fare', 'a', 'meno', 'di', 'urlare', '\"', 'Lily', '!', '\"', 'e', 'Harry', 'capì', 'che', 'era', 'un', 'bel', 'peso', ',', 'perché', 'Ron', ',', 'Hermione', ',', 'era', 'alto', 'quanto', 'un', 'calice', 'e', 'aveva', 'la', 'barba', 'di']\n","Length difference: 0\n","BLEU SCORE: 0.07569298710889658\n","----------------------------------------------------------------------------------------------------\n","Line 21\n","Reference: 17\t[['\"', 'Attualmente', 'al', 'castello', 'lavorano', 'diciotto', 'maestri', 'e', 'più', 'di', 'cinquanta', 'tra', 'allievi', 'e', 'adepti', '.', '\"']]\n","Hypotesis: 22\t['\"', 'Attualmente', 'al', 'castello', 'di', 'Nastrog', 'ho', 'solo', 'seicento', 'abitanti', ',', 'e', 'voglio', 'godere', 'ancora', 'della', 'tua', 'terra', 'e', 'dei', 'miei', 'pascoli']\n","Length difference: -5\n","BLEU SCORE: 0.12436722085116984\n","----------------------------------------------------------------------------------------------------\n","Line 22\n","Reference: 22\t[['ma', 'di', 'questo', 'passo', ',', 'non', 'avendo', 'io', 'modo', 'di', 'influire', 'sulla', 'sua', 'rotta', ',', 'come', 'potevo', 'sperare', 'di', 'prender', 'terra', '?']]\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-6306e21e46f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     output = odyssai(prompt, max_length = ref_doc_counter + 10,\n\u001b[1;32m     34\u001b[0m                     \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     do_sample = True, clean_up_tokenization_spaces = True)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mhyp_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextManipulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, return_tensors, return_text, return_full_text, clean_up_tokenization_spaces, prefix, **generate_kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 ), \"Batch generation is currently not supported. See https://github.com/huggingface/transformers/issues/3021 for more information.\"\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0moutput_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m             )\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m             )\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m         )\n\u001b[1;32m    956\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    795\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m                 )\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         )\n\u001b[1;32m    325\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"k9NutvNtlnWK"},"source":["import nltk\n","hypothesis = ['Sembrava', 'assolutamente', 'fuori', 'posto', 'in', 'quel', 'suo', 'pastrano', 'di', 'fustagno', '.'] \n","reference = ['Sembrava', 'assolutamente', 'fuori', 'posto', ',', 'in', 'una', 'cittadina', 'di', 'provincia', ',', 'a', 'quanto', 'sembrava', '.']\n","references = [reference] # list of references for 1 sentence.\n","list_of_references = [references] # list of references for all sentences in corpus.\n","list_of_hypotheses = [hypothesis] # list of hypotheses that corresponds to list of references.\n","print(nltk.translate.bleu_score.corpus_bleu(list_of_references, list_of_hypotheses))\n","print(nltk.translate.bleu_score.sentence_bleu(references, hypothesis))\n","print(list_of_references, list_of_hypotheses)\n","print(references, hypotesis)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJNxwySUoJZE","executionInfo":{"status":"ok","timestamp":1621865720633,"user_tz":-120,"elapsed":30824,"user":{"displayName":"Ivan Valluzzi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgwqlgDYbXjbiiDwveBl7NqFVOuaosSePiyzXer4w=s64","userId":"03570075665403880665"}},"outputId":"639aa583-aea0-4e17-fe75-eb8323c2bcf6"},"source":["f = open('testing_min_tokens_8.txt', 'r')\n","lines = f.readlines()\n","f.close()\n","\n","prompts = list(lines[:10])\n","\n","# for line in lines[:5]:\n","#   prompts.append(line)\n","\n","samples_outputs = odyssai(\n","  prompts,\n","  clean_up_tokenization_spaces = False,\n","  do_sample = True,\n","  max_length = 80,\n","  top_k = 50,\n","  # top_p = 0.95,\n","  temperature = 1,\n","  num_return_sequences = 1\n",")\n","\n","print('samples_outputs:', samples_outputs)\n","for i, sample_outputs in enumerate(samples_outputs):\n","  print(100 * '-')\n","  print(\"Prompt:\", prompts[i])\n","  for sample_output in sample_outputs:\n","    text = sample_output['generated_text']\n","    # print(\"Sample:\", text)\n","    print(\"Sample:\", text[:text.rfind('.')+1])\n","    print()\n","    print(\"Sample:\", text)\n","  print('sample_outputs:', sample_outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["samples_outputs: [[{'generated_text': 'Le viscere gli si strinsero come un pugno.\\nNel profondo della terra, il lento scorrere dei torrenti si incresparono in tutte le direzioni, le perle dei giganti si schiarirono e i lupi si squagliarono sotto le foglie. I loro visi si dimenticarono di colpo. \"Sì, è questo che vuoi sentire\". disse lo strigo. Il racconto di come'}], [{'generated_text': 'E lì essa rimase, che Eöl se la prese in moglie, e lungo tempo passò prima che alcuno della sua stirpe ne avesse nuovamente notizia.\\nQuando Eöl tornò in Gondolin e la chiamò Regina, essa lesse la Stella che era stata sollevata; e disse: \"Dammi la Luce, che non sei più la Luce di Valinor, se non da'}], [{'generated_text': \"Io non so cosa veramente sia svenire;\\n\\nBonhart, dopo aver attaccato te con l'arco, si era lanciato giù lungo la stradina, per recuperare quanto ti apparteneva, ma ora era disteso su una roccia su cui stava combattendo, e stava combattendo furiosamente. Il mostroquerciamente s'infilò il muschio tra le radici e\"}], [{'generated_text': 'Se non ti do qualche consiglio non te la cavi, questo è quanto io posso dire.\\nGiusto. Rimarrai nei paraggi forse due giorni e tre notti, presumo. È da un pezzo che volevo andare al lavoro. È una cosa buffa e sciocca. È una buffa e sciocca, mi pare. È buffa e sciocca. È buffa e scio'}], [{'generated_text': \"Mi ha sempre incuriosito, strigo, perché la gente abbia tanta paura di voi.\\n\\nIl vecchio Pew lasciò cadere il cappuccio blu e scese lungo la scala. Fu allora che i due si precipitarono giù da una scala più alta. Si misero l'un l'altra in sella e s'impennarono digrignando i denti. Il vecchio Pew scoppi\"}], [{'generated_text': \"Colpirlo con una spada, con tutte le forze.\\n\\nDobby non l'aveva quasi mai afferrata: la scopa le aveva lacerato la mano, l'aveva piegata come se qualcuno avesse appena tirato fuori il Mantello dell'Invisibilità. Ma, con la Maledizione Imperius che aveva sopportato, non la fece finire in tempo. Con l'\"}], [{'generated_text': 'E avrei potuto favorire meglio il mio sangue, anche se fossi giunto prima?\\n\\nEppure se fosse così, non avrei potuto, avrei potuto, se fossi riuscito, a salvare tua madre e i tuoi cari fratelli e la tua famiglia. È così che sono venuta, sei diventata una bambola di ratto. È la stessa bambola, è la stessa bambola che ho fatto a Dud'}], [{'generated_text': 'Gli avete promesso la grazia se fosse diventato testimone della corona.\\n\\nSecondo fonti ignote, il reverendo Rience sarebbe sprofondato nell\\'infermeria per quattro notti, per non raccontare tutto ciò che ha visto, tutto ciò che gli veniva ordinato dal vassallo: argento, rame, rame, lettere, lettere d\\'oro, gioielli, gioielli, gioielli. \"Secondo altre fonti'}], [{'generated_text': 'Immediatamente, la cicatrice di Harry parve aprirsi di nuovo.\\n\\nHermione, ferita al braccio, morì, il diario di Silente sepolto nella borsetta di perline. La cicatrice tremò ancora di più: la cicatrice arse dolorosamente, il frammento della mente si contorse nel vortice della cicatrice. La cicatrice tornò a ria'}], [{'generated_text': 'Non l\\'ho visto a nessuna tavola, stasera.\\nDwalin e Balin erano seduti a una scrivania a volta davanti al caminetto accanto a un fuoco ardente, e lì accanto si stavano preparando delle danze, che ognuno aveva già visto. \"Dwalin!\" gridò Bilbo con orgoglio, e i tre compagni corsero via nella direzione opposta. Smontarono giù'}]]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Le viscere gli si strinsero come un pugno.\n","\n","Sample: Le viscere gli si strinsero come un pugno.\n","Nel profondo della terra, il lento scorrere dei torrenti si incresparono in tutte le direzioni, le perle dei giganti si schiarirono e i lupi si squagliarono sotto le foglie. I loro visi si dimenticarono di colpo. \"Sì, è questo che vuoi sentire\". disse lo strigo.\n","\n","Sample: Le viscere gli si strinsero come un pugno.\n","Nel profondo della terra, il lento scorrere dei torrenti si incresparono in tutte le direzioni, le perle dei giganti si schiarirono e i lupi si squagliarono sotto le foglie. I loro visi si dimenticarono di colpo. \"Sì, è questo che vuoi sentire\". disse lo strigo. Il racconto di come\n","sample_outputs: [{'generated_text': 'Le viscere gli si strinsero come un pugno.\\nNel profondo della terra, il lento scorrere dei torrenti si incresparono in tutte le direzioni, le perle dei giganti si schiarirono e i lupi si squagliarono sotto le foglie. I loro visi si dimenticarono di colpo. \"Sì, è questo che vuoi sentire\". disse lo strigo. Il racconto di come'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: E lì essa rimase, che Eöl se la prese in moglie, e lungo tempo passò prima che alcuno della sua stirpe ne avesse nuovamente notizia.\n","\n","Sample: E lì essa rimase, che Eöl se la prese in moglie, e lungo tempo passò prima che alcuno della sua stirpe ne avesse nuovamente notizia.\n","\n","Sample: E lì essa rimase, che Eöl se la prese in moglie, e lungo tempo passò prima che alcuno della sua stirpe ne avesse nuovamente notizia.\n","Quando Eöl tornò in Gondolin e la chiamò Regina, essa lesse la Stella che era stata sollevata; e disse: \"Dammi la Luce, che non sei più la Luce di Valinor, se non da\n","sample_outputs: [{'generated_text': 'E lì essa rimase, che Eöl se la prese in moglie, e lungo tempo passò prima che alcuno della sua stirpe ne avesse nuovamente notizia.\\nQuando Eöl tornò in Gondolin e la chiamò Regina, essa lesse la Stella che era stata sollevata; e disse: \"Dammi la Luce, che non sei più la Luce di Valinor, se non da'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Io non so cosa veramente sia svenire;\n","\n","Sample: Io non so cosa veramente sia svenire;\n","\n","Bonhart, dopo aver attaccato te con l'arco, si era lanciato giù lungo la stradina, per recuperare quanto ti apparteneva, ma ora era disteso su una roccia su cui stava combattendo, e stava combattendo furiosamente.\n","\n","Sample: Io non so cosa veramente sia svenire;\n","\n","Bonhart, dopo aver attaccato te con l'arco, si era lanciato giù lungo la stradina, per recuperare quanto ti apparteneva, ma ora era disteso su una roccia su cui stava combattendo, e stava combattendo furiosamente. Il mostroquerciamente s'infilò il muschio tra le radici e\n","sample_outputs: [{'generated_text': \"Io non so cosa veramente sia svenire;\\n\\nBonhart, dopo aver attaccato te con l'arco, si era lanciato giù lungo la stradina, per recuperare quanto ti apparteneva, ma ora era disteso su una roccia su cui stava combattendo, e stava combattendo furiosamente. Il mostroquerciamente s'infilò il muschio tra le radici e\"}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Se non ti do qualche consiglio non te la cavi, questo è quanto io posso dire.\n","\n","Sample: Se non ti do qualche consiglio non te la cavi, questo è quanto io posso dire.\n","Giusto. Rimarrai nei paraggi forse due giorni e tre notti, presumo. È da un pezzo che volevo andare al lavoro. È una cosa buffa e sciocca. È una buffa e sciocca, mi pare. È buffa e sciocca.\n","\n","Sample: Se non ti do qualche consiglio non te la cavi, questo è quanto io posso dire.\n","Giusto. Rimarrai nei paraggi forse due giorni e tre notti, presumo. È da un pezzo che volevo andare al lavoro. È una cosa buffa e sciocca. È una buffa e sciocca, mi pare. È buffa e sciocca. È buffa e scio\n","sample_outputs: [{'generated_text': 'Se non ti do qualche consiglio non te la cavi, questo è quanto io posso dire.\\nGiusto. Rimarrai nei paraggi forse due giorni e tre notti, presumo. È da un pezzo che volevo andare al lavoro. È una cosa buffa e sciocca. È una buffa e sciocca, mi pare. È buffa e sciocca. È buffa e scio'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Mi ha sempre incuriosito, strigo, perché la gente abbia tanta paura di voi.\n","\n","Sample: Mi ha sempre incuriosito, strigo, perché la gente abbia tanta paura di voi.\n","\n","Il vecchio Pew lasciò cadere il cappuccio blu e scese lungo la scala. Fu allora che i due si precipitarono giù da una scala più alta. Si misero l'un l'altra in sella e s'impennarono digrignando i denti.\n","\n","Sample: Mi ha sempre incuriosito, strigo, perché la gente abbia tanta paura di voi.\n","\n","Il vecchio Pew lasciò cadere il cappuccio blu e scese lungo la scala. Fu allora che i due si precipitarono giù da una scala più alta. Si misero l'un l'altra in sella e s'impennarono digrignando i denti. Il vecchio Pew scoppi\n","sample_outputs: [{'generated_text': \"Mi ha sempre incuriosito, strigo, perché la gente abbia tanta paura di voi.\\n\\nIl vecchio Pew lasciò cadere il cappuccio blu e scese lungo la scala. Fu allora che i due si precipitarono giù da una scala più alta. Si misero l'un l'altra in sella e s'impennarono digrignando i denti. Il vecchio Pew scoppi\"}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Colpirlo con una spada, con tutte le forze.\n","\n","Sample: Colpirlo con una spada, con tutte le forze.\n","\n","Dobby non l'aveva quasi mai afferrata: la scopa le aveva lacerato la mano, l'aveva piegata come se qualcuno avesse appena tirato fuori il Mantello dell'Invisibilità. Ma, con la Maledizione Imperius che aveva sopportato, non la fece finire in tempo.\n","\n","Sample: Colpirlo con una spada, con tutte le forze.\n","\n","Dobby non l'aveva quasi mai afferrata: la scopa le aveva lacerato la mano, l'aveva piegata come se qualcuno avesse appena tirato fuori il Mantello dell'Invisibilità. Ma, con la Maledizione Imperius che aveva sopportato, non la fece finire in tempo. Con l'\n","sample_outputs: [{'generated_text': \"Colpirlo con una spada, con tutte le forze.\\n\\nDobby non l'aveva quasi mai afferrata: la scopa le aveva lacerato la mano, l'aveva piegata come se qualcuno avesse appena tirato fuori il Mantello dell'Invisibilità. Ma, con la Maledizione Imperius che aveva sopportato, non la fece finire in tempo. Con l'\"}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: E avrei potuto favorire meglio il mio sangue, anche se fossi giunto prima?\n","\n","Sample: E avrei potuto favorire meglio il mio sangue, anche se fossi giunto prima?\n","\n","Eppure se fosse così, non avrei potuto, avrei potuto, se fossi riuscito, a salvare tua madre e i tuoi cari fratelli e la tua famiglia. È così che sono venuta, sei diventata una bambola di ratto.\n","\n","Sample: E avrei potuto favorire meglio il mio sangue, anche se fossi giunto prima?\n","\n","Eppure se fosse così, non avrei potuto, avrei potuto, se fossi riuscito, a salvare tua madre e i tuoi cari fratelli e la tua famiglia. È così che sono venuta, sei diventata una bambola di ratto. È la stessa bambola, è la stessa bambola che ho fatto a Dud\n","sample_outputs: [{'generated_text': 'E avrei potuto favorire meglio il mio sangue, anche se fossi giunto prima?\\n\\nEppure se fosse così, non avrei potuto, avrei potuto, se fossi riuscito, a salvare tua madre e i tuoi cari fratelli e la tua famiglia. È così che sono venuta, sei diventata una bambola di ratto. È la stessa bambola, è la stessa bambola che ho fatto a Dud'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Gli avete promesso la grazia se fosse diventato testimone della corona.\n","\n","Sample: Gli avete promesso la grazia se fosse diventato testimone della corona.\n","\n","Secondo fonti ignote, il reverendo Rience sarebbe sprofondato nell'infermeria per quattro notti, per non raccontare tutto ciò che ha visto, tutto ciò che gli veniva ordinato dal vassallo: argento, rame, rame, lettere, lettere d'oro, gioielli, gioielli, gioielli.\n","\n","Sample: Gli avete promesso la grazia se fosse diventato testimone della corona.\n","\n","Secondo fonti ignote, il reverendo Rience sarebbe sprofondato nell'infermeria per quattro notti, per non raccontare tutto ciò che ha visto, tutto ciò che gli veniva ordinato dal vassallo: argento, rame, rame, lettere, lettere d'oro, gioielli, gioielli, gioielli. \"Secondo altre fonti\n","sample_outputs: [{'generated_text': 'Gli avete promesso la grazia se fosse diventato testimone della corona.\\n\\nSecondo fonti ignote, il reverendo Rience sarebbe sprofondato nell\\'infermeria per quattro notti, per non raccontare tutto ciò che ha visto, tutto ciò che gli veniva ordinato dal vassallo: argento, rame, rame, lettere, lettere d\\'oro, gioielli, gioielli, gioielli. \"Secondo altre fonti'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Immediatamente, la cicatrice di Harry parve aprirsi di nuovo.\n","\n","Sample: Immediatamente, la cicatrice di Harry parve aprirsi di nuovo.\n","\n","Hermione, ferita al braccio, morì, il diario di Silente sepolto nella borsetta di perline. La cicatrice tremò ancora di più: la cicatrice arse dolorosamente, il frammento della mente si contorse nel vortice della cicatrice.\n","\n","Sample: Immediatamente, la cicatrice di Harry parve aprirsi di nuovo.\n","\n","Hermione, ferita al braccio, morì, il diario di Silente sepolto nella borsetta di perline. La cicatrice tremò ancora di più: la cicatrice arse dolorosamente, il frammento della mente si contorse nel vortice della cicatrice. La cicatrice tornò a ria\n","sample_outputs: [{'generated_text': 'Immediatamente, la cicatrice di Harry parve aprirsi di nuovo.\\n\\nHermione, ferita al braccio, morì, il diario di Silente sepolto nella borsetta di perline. La cicatrice tremò ancora di più: la cicatrice arse dolorosamente, il frammento della mente si contorse nel vortice della cicatrice. La cicatrice tornò a ria'}]\n","----------------------------------------------------------------------------------------------------\n","Prompt: Non l'ho visto a nessuna tavola, stasera.\n","\n","Sample: Non l'ho visto a nessuna tavola, stasera.\n","Dwalin e Balin erano seduti a una scrivania a volta davanti al caminetto accanto a un fuoco ardente, e lì accanto si stavano preparando delle danze, che ognuno aveva già visto. \"Dwalin!\" gridò Bilbo con orgoglio, e i tre compagni corsero via nella direzione opposta.\n","\n","Sample: Non l'ho visto a nessuna tavola, stasera.\n","Dwalin e Balin erano seduti a una scrivania a volta davanti al caminetto accanto a un fuoco ardente, e lì accanto si stavano preparando delle danze, che ognuno aveva già visto. \"Dwalin!\" gridò Bilbo con orgoglio, e i tre compagni corsero via nella direzione opposta. Smontarono giù\n","sample_outputs: [{'generated_text': 'Non l\\'ho visto a nessuna tavola, stasera.\\nDwalin e Balin erano seduti a una scrivania a volta davanti al caminetto accanto a un fuoco ardente, e lì accanto si stavano preparando delle danze, che ognuno aveva già visto. \"Dwalin!\" gridò Bilbo con orgoglio, e i tre compagni corsero via nella direzione opposta. Smontarono giù'}]\n"],"name":"stdout"}]}]}